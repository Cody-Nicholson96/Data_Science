# Data Preprocessing

### 1. Data Cleaning

- Filling in missing values
    + Average, median, mode
- Smoothing noisy data
    + (equal-depth, equal-width)
    + Clustering,

***

### 2. Data Integration

- Detect and remove any data inconstancies
- Data redundancy
    + Correlation analysis (-1 <= r <= 1)

***

### 3. Data Transformation

- Smoothing the data
- Plugging in missing values
- Aggregation: summarizing the data (Min, Q1, Median, Q3, Max) and by using Mu and Sigma
- Normalize, scaled to fall within a small, specific range
    + min-max normalization
    + z-scale normalization
    + normalization by decimal scaling
- Construct new attributes

***

When should I choose the correlation metrics over the covariance metrics when analyzing the data redundancy

When should I use min.max normalization, z-scale normalization, and normalization by decimal scaling
